,,,,,,,,,,,
,,,,,,,,,,,
Participant ID,What is your experience with RL?,What is your experience with AI?,"Have you designed a reward function before? If so, what domain have you designed a reward function for? (Mark all that apply)","How did you design the reward function? Or if you have not designed a reward function before, how would you write a reward function? 
(Mark all that apply.) ",How did (or would) you evaluate a reward function(s)?,Did you observe suboptimal behavior after training your agent?,"During the reward design process, would it be useful to have a metric that helps distinguish between the quality of reward functions?",How old are you?,What is the highest level of education you have completed?,What gender do you identify with?,Which race or ethnicity best describes you? 
7,"I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code., I currently work at a job where I use reinforcement learning., Read books/papers in RL","I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code., I currently work at a job where I use AI.",for Finance,"By applying intuition and considering how the agent would learn, By embedding domain knowledge of how the agent should behave","By viewing the agent’s behavior after it has finished training (and would not be trained further), By viewing the agent’s behavior during a training session (that was continued further), By plotting some performance metric against time or learning iterations, By plotting return from the reward function against time or learning iterations, By scoring example trajectories","Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed something other than the reward function. This can include the learning algorithm, hyperparameters, etc.",Yes,,Master's degree,Male,Middle Eastern or North African
8,"I have taken a graduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code.","I have taken an undergraduate course in AI., I have taken a graduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code.","Yes, a gridworld task, Yes,  a classic RL task – like CartPole or Mountain Car","By applying intuition and considering how the agent would learn, By embedding domain knowledge of how the agent should behave, Using a reward function someone else had written (e.g., from a publication or shared implementation)","By viewing the agent’s behavior after it has finished training (and would not be trained further), By plotting some performance metric against time or learning iterations, By plotting return from the reward function against time or learning iterations, Not scoring the trajectories. But somehow I should check if the reward I gave to the agent resulted in the correct policies or not","Yes - I observed the agent taking advantage of a loophole in the reward function, so I changed the function to remove the loophole., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed something other than the reward function. This can include the learning algorithm, hyperparameters, etc.",Yes,25-30,Bachelor's degree,Female,Not listed
10,"I have taken an undergraduate course in RL., I have taken a graduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code.","I have taken an undergraduate course in AI., I have taken a graduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code.","No, I have not designed a reward function.","By applying intuition and considering how the agent would learn, By embedding domain knowledge of how the agent should behave, Using a reward function someone else had written (e.g., from a publication or shared implementation)","By viewing the agent’s behavior after it has finished training (and would not be trained further), By plotting some performance metric against time or learning iterations, By scoring example trajectories",NA -- I have never designed a reward function.,Yes,31-40,Master's degree,Female,White / Caucasian
6,"I have taken a graduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code.","I have taken a graduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code.","Yes,  a classic RL task – like CartPole or Mountain Car, Yes, a robotics task","By embedding domain knowledge of how the agent should behave, Using a reward function someone else had written (e.g., from a publication or shared implementation)","By viewing the agent’s behavior during a training session (that was continued further), By plotting some performance metric against time or learning iterations, By plotting return from the reward function against time or learning iterations","Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed something other than the reward function. This can include the learning algorithm, hyperparameters, etc.",Yes,31-40,Master's degree,Male,Middle Eastern or North African
1,"I have taken an undergraduate course in RL., I have taken a graduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code., I currently work at a job where I use reinforcement learning.","I have taken an undergraduate course in AI., I have taken a graduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code., I currently work at a job where I use AI.","Yes, a gridworld task","By applying intuition and considering how the agent would learn, By embedding domain knowledge of how the agent should behave, Using a reward function someone else had written (e.g., from a publication or shared implementation)","By viewing the agent’s behavior after it has finished training (and would not be trained further), By viewing the agent’s behavior during a training session (that was continued further), By scoring example trajectories","Yes - I observed the agent taking advantage of a loophole in the reward function, so I changed the function to remove the loophole.",Yes,25-30,Bachelor's degree,Male,Middle Eastern or North African
2,"I have taken an undergraduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code.","I have taken an undergraduate course in AI., I have taken a graduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code.","Yes, a gridworld task, Yes, a multi-agent task (e.g., Hanabi)","By embedding domain knowledge of how the agent should behave, Using a reward function someone else had written (e.g., from a publication or shared implementation)","By viewing the agent’s behavior after it has finished training (and would not be trained further), By plotting some performance metric against time or learning iterations, By plotting return from the reward function against time or learning iterations","Yes - I observed the agent taking advantage of a loophole in the reward function, so I changed the function to remove the loophole., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed the reward function to help it improve its performance., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed something other than the reward function. This can include the learning algorithm, hyperparameters, etc.",Yes,25-30,Bachelor's degree,Male,South Asian
5,"I have taken an undergraduate course in RL., I have taken a graduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have used or implemented an RL algorithm in code.","I have taken an undergraduate course in AI., I have taken a graduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code.","Yes, a gridworld task, Yes,  a classic RL task – like CartPole or Mountain Car, Yes, a robotics task","By applying intuition and considering how the agent would learn, By embedding domain knowledge of how the agent should behave, Learning a reward function (e.g., inverse RL or preference based RL)","By viewing the agent’s behavior after it has finished training (and would not be trained further), By viewing the agent’s behavior during a training session (that was continued further), By plotting some performance metric against time or learning iterations, By plotting return from the reward function against time or learning iterations","Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed the reward function to help it improve its performance., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed something other than the reward function. This can include the learning algorithm, hyperparameters, etc.",Yes,18-24,High school Diploma,Male,"East Asian, White / Caucasian, Multi-racial"
11,"I have taken an undergraduate course in RL., I have taken a graduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code.","I have taken an undergraduate course in AI., I have taken a graduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code.","Yes, a gridworld task","By applying intuition and considering how the agent would learn, By embedding domain knowledge of how the agent should behave, Using a reward function someone else had written (e.g., from a publication or shared implementation)","By viewing the agent’s behavior after it has finished training (and would not be trained further), By viewing the agent’s behavior during a training session (that was continued further), By plotting some performance metric against time or learning iterations, By plotting return from the reward function against time or learning iterations","Yes - I observed the agent taking advantage of a loophole in the reward function, so I changed the function to remove the loophole., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed the reward function to help it improve its performance., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed something other than the reward function. This can include the learning algorithm, hyperparameters, etc.",Yes,18-24,Bachelor's degree,Male,East Asian
4,"I have taken an undergraduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code.","I have taken an undergraduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code.","No, I have not designed a reward function.","By applying intuition and considering how the agent would learn, By embedding domain knowledge of how the agent should behave, Using a reward function someone else had written (e.g., from a publication or shared implementation), Learning a reward function (e.g., inverse RL or preference based RL)","By viewing the agent’s behavior after it has finished training (and would not be trained further), By viewing the agent’s behavior during a training session (that was continued further), By plotting some performance metric against time or learning iterations, By plotting return from the reward function against time or learning iterations, By scoring example trajectories",NA -- I have never designed a reward function.,Yes,18-24,High school Diploma,Female,"East Asian, South Asian"
9,"I have taken a graduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code.","I have taken an undergraduate course in AI., I have taken a graduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code.","Yes, a gridworld task, Yes,  a classic RL task – like CartPole or Mountain Car, Yes, an Atari game or other game, The real world application like chip design","By applying intuition and considering how the agent would learn, By embedding domain knowledge of how the agent should behave, Using a reward function someone else had written (e.g., from a publication or shared implementation)","By viewing the agent’s behavior after it has finished training (and would not be trained further), By viewing the agent’s behavior during a training session (that was continued further), By plotting some performance metric against time or learning iterations, By plotting return from the reward function against time or learning iterations","Yes - I observed the agent taking advantage of a loophole in the reward function, so I changed the function to remove the loophole., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed the reward function to help it improve its performance., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed something other than the reward function. This can include the learning algorithm, hyperparameters, etc.",Yes,25-30,Master's degree,Male,East Asian
3,"I have taken a graduate course in RL., I have learned about RL via Youtube/Coursera/Udemy, etc., I have done research in RL., I have used or implemented an RL algorithm in code., I currently work at a job where I use reinforcement learning.","I have taken an undergraduate course in AI., I have taken a graduate course in AI., I have learned about AI via Youtube/Coursera/Udemy, etc., I have done research in AI., I have used or implemented an AI algorithm in code., I currently work at a job where I use AI.","Yes, a gridworld task, Yes,  a classic RL task – like CartPole or Mountain Car, Yes, a robotics task","By applying intuition and considering how the agent would learn, By embedding domain knowledge of how the agent should behave, Using a reward function someone else had written (e.g., from a publication or shared implementation)","By viewing the agent’s behavior after it has finished training (and would not be trained further), By viewing the agent’s behavior during a training session (that was continued further), By plotting some performance metric against time or learning iterations, By plotting return from the reward function against time or learning iterations","Yes - I observed the agent taking advantage of a loophole in the reward function, so I changed the function to remove the loophole., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed the reward function to help it improve its performance., Yes - I observed the agent’s behavior plateauing at unsatisfactory performance, so I changed something other than the reward function. This can include the learning algorithm, hyperparameters, etc.",Yes,25-30,Master's degree,Male,East Asian