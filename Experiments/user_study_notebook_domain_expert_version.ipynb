{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafed085-6f42-4f9b-bf84-82cb72b34152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import notebooks; do not edit\n",
    "import user_study_interface_backend_domain_expert\n",
    "\n",
    "#researcher change the seed\n",
    "interface = user_study_interface_backend_domain_expert.interface_backend(random_seed=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfdd4d0-fad7-4d99-8d85-598c15c6f21e",
   "metadata": {},
   "source": [
    "## Get Study ID, run the cell below and enter your name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0f280-68e1-452e-9480-98b01056cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell and enter your name. \n",
    "\n",
    "interface.set_study_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d477896-adee-44c7-b363-31d27aea24bb",
   "metadata": {},
   "source": [
    "# **Task 0: Understanding the Domain: Hungry-Thirsty** \n",
    "**Read the following description:** <br>\n",
    "\n",
    "**The Basics:** \n",
    "\n",
    "The goal of the hungry-thirsty domain is to teach an agent to eat food as much as possible.\n",
    "There's a catch, though: *the agent can only eat when it's not thirsty*.  Thus, the agent cannot\n",
    "just “hang out” at the food location and keep eating because at\n",
    "some point it will become thirsty, and the agent cannot eat while it is thirsty.\n",
    "\n",
    "**Actions:** At each timestep, the agent may take one of the following actions: move (up, down, left, right), eat, or drink.     <br>\n",
    "    \n",
    "**Hunger and Thirst:** \n",
    "* If the agent drinks, it becomes not thirsty.<br>\n",
    "* At each timestep, the agent has a 10% probability of becoming thirsty. <br>\n",
    "* If the agent eats while not thirsty, it successfully eats the food and becomes not hungry for one timestep. <br>\n",
    "* The agent's goal is to be not hungry for as many timesteps as possible.\n",
    "   \n",
    "**How Actions Can Fail:** \n",
    "\n",
    "* The drink action fails if the agent is not at the water location.\n",
    "* The eat action fails if the agent is thirsty, or if the agent is not at the food location.\n",
    "* The move action fails if the agent tries to move through one of the red barriers (depicted below).\n",
    "\n",
    "\n",
    "**Other Information:** \n",
    "* The agent's state consists of its (x,y) coordinates and two boolean variables for hunger and thirst.\n",
    "* We provide full information of the agent's history (i.e., how many times the agent is (hungry, thirsty), (hungry, not thirsty),etc). \n",
    "* Each episode lasts for 200 timesteps.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7dfd9-bdd8-46c0-a78b-b7f1e523a48b",
   "metadata": {},
   "source": [
    "## Run the code below to show a gif of the agent acting in a sped up version of the domain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752793c-8e0a-45ad-aebb-149b04fe027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell shows the agent acting in a sped up version of the domain\n",
    "from IPython.display import Image\n",
    "Image(\"User_Study_Data/TrajsGifs/same_start_state/demo_gif.gif\", width=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c141f31b-46bb-4880-a494-d73e1216be35",
   "metadata": {},
   "source": [
    "## Run the code below to control an agent in the domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717378e4-54c4-494f-94bc-63f3a25bb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "interface.allow_user_control()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f77d869-4854-4987-9723-f9ec77c2350d",
   "metadata": {},
   "source": [
    "## Other characteristics of the environment you might have noticed while playing:\n",
    "* If the agent is both hungry and thirsty for one timestep, the cell will remain white.\n",
    "* If the agent successfully drinks, it becomes not thirsty, and the cell will turn <span style=\"color: blue;\">blue</span>.<br>\n",
    "* If the agent is not hungry, the cell will turn <span style=\"color: green;\">green</span>. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800b12eb-77aa-4041-940e-965193611486",
   "metadata": {},
   "source": [
    "## Environment Understanding Check-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b5ca3-3069-44f7-9b5a-9785c7f98b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell\n",
    "interface.env_understanding_checkin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28871c-4f09-4763-8d60-ad1bdd01cbdf",
   "metadata": {},
   "source": [
    "# **Task 1: Understanding the Domain Expert's Preferences**  \n",
    "Imagine you're working alongside a **domain expert** in the Hungry-Thirsty environment. The domain expert has spent a lot of time and effort observing the agent’s behavior and carefully ranked 12 different trajectories from **best to worst**, based on the agent's success in the task.  \n",
    "**Assume that the domain expert is the source of ground truth.** \n",
    "\n",
    "However, while the expert knows how to judge the degree of task success, they **cannot define a reward function themselves**. \n",
    "\n",
    "As **someone with RL experience**, your job in this task is to **watch the video clips, review the rankings, and understand what the expert values most in the consequences of agent behavior**.  \n",
    "\n",
    "\n",
    "This understanding will be important for your next step.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e04a912-4e6b-4131-b285-826bfe49fa26",
   "metadata": {},
   "source": [
    "## Rankings from a Domain Expert\n",
    "**You will watch the trajectories from best to worst, sequentially. Then you can re-rewatch any trajectory you like.**\n",
    "\n",
    "<b>Rank 1:</b> Traj. I <span style=\"color: green;\">(Best)</span><br>  \n",
    "<b>Rank 2:</b> Traj. K<br>  \n",
    "<b>Rank 3:</b> Traj. L<br>  \n",
    "<b>Rank 4:</b> Traj. J<br>  \n",
    "<b>Rank 5:</b> Traj. E<br>  \n",
    "<b>Rank 6:</b> Traj. G<br>  \n",
    "<b>Rank 7:</b> Traj. F<br>  \n",
    "<b>Rank 8:</b> Traj. H<br>  \n",
    "<b>Rank 9:</b> Traj. C<br>  \n",
    "<b>Rank 10:</b> Traj. A<br>  \n",
    "<b>Rank 11:</b> Traj. D<br>  \n",
    "<b>Rank 12:</b> Traj. B <span style=\"color: red;\">(Worst)</span><br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb444e53-d89d-45bd-b5f8-93188587d462",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this cell to begin task 1\n",
    "interface.studypart1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6ac46-3f04-4159-a06b-a35267b61592",
   "metadata": {},
   "source": [
    "# **Task 2: Choosing the Best Reward Function**  \n",
    "Now it’s time to take on your **role as an RL practitioner**. Your goal is to **choose a reward function that best aligns with the domain expert’s preferences**.  \n",
    "\n",
    "Since the domain expert cannot directly define a reward function, they are relying on you to translate their rankings into a meaningful reward function that teaches the agent to behave as they expect.  \n",
    "\n",
    "You will compare **four pairs of reward functions** (i.e., make four pairwise comparisons). Each pair represents two different ways of rewarding agent behavior in the Hungry-Thirsty environment.  \n",
    "\n",
    "Your task is to **select the reward function that best captures what the expert values**.  \n",
    "\n",
    "To assist you, you will perform these comparisons under **three different conditions**, each providing different information to guide your decision.  \n",
    "\n",
    "**The reward is a function of hunger and thirst. It is provided per time step. Reward functions differ by the values assigned to a, b, c, and d.**\n",
    "<br> `hungry and thirsty` = a\n",
    "<br> `hungry and not thirsty` = b\n",
    "<br>`not hungry and thirsty` = c\n",
    "<br>`not hungry and not thirsty` = d\n",
    "\n",
    "Example of a possible reward function:\n",
    "<br> `hungry and thirsty` = 200\n",
    "<br> `hungry and not thirsty` = -1\n",
    "<br>`not hungry and thirsty` = -10\n",
    "<br>`not hungry and not thirsty` = -5\n",
    "\n",
    "**Reminder of the task:**\n",
    "<br>The goal of the hungry-thirsty domain is to teach an agent to eat as much as possible. There's a catch, though: *the agent can only eat when it's not thirsty*. Thus, the agent cannot\n",
    "just “hang out” at the food location and keep eating because at some point it will become thirsty and eating will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694825c7-a873-493a-bdd3-d07f7b695107",
   "metadata": {},
   "source": [
    "### Condition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e683fd-fc7e-4ba0-a0d6-787f50461063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### run this cell\n",
    "interface.function_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1de09-2601-474a-98e7-03bfe9b27996",
   "metadata": {},
   "source": [
    "### Survey 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5278286c-3780-417a-a4f9-329a59aef6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "interface.condition_survey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aeb765-982d-46a6-b5a8-7770e0d2f039",
   "metadata": {},
   "source": [
    "### Condition 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4f410-f1dc-4523-9e68-7d51a9253402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### # run this cell\n",
    "interface.function_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b0797b-4fd0-4b05-92ef-eb2b337afa23",
   "metadata": {},
   "source": [
    "### Survey 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9349f-7f4f-4756-926a-c7a7db4288e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "interface.condition_survey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3aba9d-1292-4565-bb20-18c08df36adc",
   "metadata": {},
   "source": [
    "### Condition 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3810e8-651e-43b4-9622-8a06e44a8702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "interface.function_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ea756d-16b5-4d89-8526-0fe3839eabda",
   "metadata": {},
   "source": [
    "### Survey 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2074f-2927-4ec2-ac59-8d79d1ac7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell \n",
    "interface.condition_survey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f9787-0e46-4a5d-9040-01ca69a2e75d",
   "metadata": {},
   "source": [
    "### Final Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806598f6-5b1f-43fd-bc04-8f47fe7192d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell \n",
    "interface.print_condition_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1668242-350f-4bea-9379-ed7ac7969d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell \n",
    "interface.final_survey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc14111-e6bc-4aad-b9a2-b0c903bcbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.data_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bddc543-a86a-4f10-964e-74f32adf1cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
